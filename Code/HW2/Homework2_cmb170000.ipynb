{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Assignment 3: Exploring NLTK\n",
    "Author: Six Wires\n",
    "Instructor: Mazidi\n",
    "Subject: CS 4396\n",
    "Date: September 10, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.collections import *\n",
    "from nltk.stem import *\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Use the tokens method to extract 20 tokens from text1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "source": [
    "print(text1.tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Use concordance method on the word \"sea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 455 matches:\n",
      " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
      " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
      "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
      "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
      " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# look for instances of sea and print sentences\n",
    "print(text1.concordance('sea', 80, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Look at the nltk count() method. How is it different from python's count method?\n",
    "NLTK's count method prints the number of times the parameter word appears in the calling text object, Pythonâ€™s version is case sensitive but seems to do pretty much the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python's count method: 7\n",
      "NLTK's count method: 7\n"
     ]
    }
   ],
   "source": [
    "# Create default text\n",
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "\n",
    "# Python's count method:\n",
    "print(\"Python's count method:\", text.count(\"in\"))\n",
    "\n",
    "# NLTK's count method:\n",
    "print(\"NLTK's count method:\", text.count(\"in\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6: Using raw text of at least 5 sentences of your choice from any source (cite the source), save the text into a variable called raw_text. Using NLTK's word tokenizer tokenize the text into variable 'tokens'. Print the first 10 tokens. \n",
    "\n",
    "[Link to text source](https://www.lipsum.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define raw text\n",
    "raw_text = \"He has obstructed the Administration of Justice by refusing his Assent to Laws for establishing Judiciary Powers. He has made Judges dependent on his Will alone for the tenure of their offices, and the amount and payment of their salaries. He has erected a multitude of New Offices, and sent hither swarms of Officers to harass our people and eat out their substance. He has kept among us, in times of peace, Standing Armies without the Consent of our legislatures. He has affected to render the Military independent of and superior to the Civil Power.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'has', 'obstructed', 'the', 'Administration', 'of', 'Justice', 'by', 'refusing', 'his']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the raw text\n",
    "tokens = word_tokenize(raw_text)\n",
    "\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7: Using the same raw text, and NLTK's sentence tokenizer sent_tokenize(), perform sentence segmentation and display the sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He has obstructed the Administration of Justice by refusing his Assent to Laws for establishing Judiciary Powers.', 'He has made Judges dependent on his Will alone for the tenure of their offices, and the amount and payment of their salaries.', 'He has erected a multitude of New Offices, and sent hither swarms of Officers to harass our people and eat out their substance.', 'He has kept among us, in times of peace, Standing Armies without the Consent of our legislatures.', 'He has affected to render the Military independent of and superior to the Civil Power.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(raw_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8:  Using NLTK's PorterStemmer(), write a list comprehension to stem the text. Display the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'ha', 'obstruct', 'the', 'administr', 'of', 'justic', 'by', 'refus', 'hi', 'assent', 'to', 'law', 'for', 'establish', 'judiciari', 'power', '.', 'he', 'ha', 'made', 'judg', 'depend', 'on', 'hi', 'will', 'alon', 'for', 'the', 'tenur', 'of', 'their', 'offic', ',', 'and', 'the', 'amount', 'and', 'payment', 'of', 'their', 'salari', '.', 'he', 'ha', 'erect', 'a', 'multitud', 'of', 'new', 'offic', ',', 'and', 'sent', 'hither', 'swarm', 'of', 'offic', 'to', 'harass', 'our', 'peopl', 'and', 'eat', 'out', 'their', 'substanc', '.', 'he', 'ha', 'kept', 'among', 'us', ',', 'in', 'time', 'of', 'peac', ',', 'stand', 'armi', 'without', 'the', 'consent', 'of', 'our', 'legislatur', '.', 'he', 'ha', 'affect', 'to', 'render', 'the', 'militari', 'independ', 'of', 'and', 'superior', 'to', 'the', 'civil', 'power', '.']\n"
     ]
    }
   ],
   "source": [
    "# Create stemmer and print out stems\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in word_tokenize(raw_text)]\n",
    "\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9: Using NLTK's WordNetLemmatizer, write a list comprehension to lemmatize the text Display the list. In the text cell above this code cell, list at least 5 differences you see in the stems verses the lemmas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences:\n",
    "\n",
    "Stem      - Lemma\n",
    "* he        - He\n",
    "* obstruct  - obstructed\n",
    "* administr - Administration\n",
    "* justic    - Justice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'ha', 'obstructed', 'the', 'Administration', 'of', 'Justice', 'by', 'refusing', 'his', 'Assent', 'to', 'Laws', 'for', 'establishing', 'Judiciary', 'Powers', '.', 'He', 'ha', 'made', 'Judges', 'dependent', 'on', 'his', 'Will', 'alone', 'for', 'the', 'tenure', 'of', 'their', 'office', ',', 'and', 'the', 'amount', 'and', 'payment', 'of', 'their', 'salary', '.', 'He', 'ha', 'erected', 'a', 'multitude', 'of', 'New', 'Offices', ',', 'and', 'sent', 'hither', 'swarm', 'of', 'Officers', 'to', 'harass', 'our', 'people', 'and', 'eat', 'out', 'their', 'substance', '.', 'He', 'ha', 'kept', 'among', 'u', ',', 'in', 'time', 'of', 'peace', ',', 'Standing', 'Armies', 'without', 'the', 'Consent', 'of', 'our', 'legislature', '.', 'He', 'ha', 'affected', 'to', 'render', 'the', 'Military', 'independent', 'of', 'and', 'superior', 'to', 'the', 'Civil', 'Power', '.']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(word) for word in word_tokenize(raw_text)]\n",
    "\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10: My opinion of the NLTK Library\n",
    "I think the NLTK library is very in depth and has a meriad of features. The code is very simple to use and easy to understand, and the functions are written cleanly. I could see myself using tokenizers like the one above to analyze sentences and their structure. The lemmatizer seemed to be less harsh than the stemmer, and I may use the lemmatizer to help analyze tone in sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('nlp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b0c4754b13b081436b1173ea436c6589f50c87812c69e1b595fd123fd945230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
